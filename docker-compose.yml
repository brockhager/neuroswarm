version: '3.8'

services:
  # NS-LLM Backend (C++ + ONNX Runtime)
  ns-llm:
    build:
      context: .
      dockerfile: NS-LLM/Dockerfile
    container_name: ns-llm
    ports:
      - "8080:8080"
    volumes:
      - ./NS-LLM/models:/app/models
    environment:
      - MODEL_PATH=/app/models
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "echo", '{"cmd":"health"}', "|", "/usr/local/bin/ns-llm-native" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # NS Node (Node.js API Server)
  ns-node:
    build:
      context: .
      dockerfile: ns-node/Dockerfile
    container_name: ns-node
    ports:
      - "3009:3009"
    environment:
      - PORT=3009
      - NS_LLM_URL=http://ns-llm:8080
      - NODE_ENV=production
    depends_on:
      ns-llm:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "node", "-e", "require('http').get('http://localhost:3009/health', (r) => { process.exit(r.statusCode === 200 ? 0 : 1); })" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # NS Web (React Frontend)
  ns-web:
    build:
      context: .
      dockerfile: ns-web/Dockerfile
    container_name: ns-web
    ports:
      - "3010:3010"
    depends_on:
      ns-node:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3010/" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

volumes:
  models:
    driver: local

networks:
  default:
    name: ns-network
